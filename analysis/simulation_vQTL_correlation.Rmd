---
title: "Quantile regression for vQTLs"
author: "Ziang Zhang"
date: "2024-12-06"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(BayesGP)
library(TMB)
library(Matrix)
library(splines)
library(parallel)
library(ggplot2)
library(reshape2)
library(mixsqp)
library(tidyverse)
library(mashr)
library(quantreg)
cpp_dir <- paste0(getwd(), "/code/cpp")
function_dir <- paste0(getwd(), "/code/function")
result_dir <- paste0(getwd(), "/output/vQTL_correlated")
data_dir <- paste0(getwd(), "/data/vQTL_correlated")
source(paste0(function_dir, "/functions_fitting_Gaussian_unequal.R"))
TMB::compile(paste0(cpp_dir, "/Gaussian_theta_known_unequal.cpp"))
TMB::compile(paste0(cpp_dir, "/Gaussian_just_fixed_unequal.cpp"))
dyn.load(TMB::dynlib(paste0(cpp_dir, "/Gaussian_theta_known_unequal")))
dyn.load(TMB::dynlib(paste0(cpp_dir, "/Gaussian_just_fixed_unequal")))
```


## *Introduction*

In this example, we examined the performance of FASH in detecting vQTLs based on the output from quantile regression. 
For a given SNP $G$ and a continuous trait $Y$, the quantile regression model is given by
\[
Q_Y(\tau|G = g) = g\beta(\tau),
\]
where $Q_Y(\tau|G = g)$ is the $\tau$-th quantile of $Y$ given $G = g$, and $\beta(\tau)$ is the effect size of $G$ on the $\tau$-th quantile of $Y$.

In [Miao et al., 2022](https://www.pnas.org/doi/epub/10.1073/pnas.2212959119), the authors proposed an approach called QUAIL, which uses quantile regression to detect vQTLs.
Specifically, if the SNP $G$ has effect on the variance of $Y$, then its quantile effect $\beta(\tau)$ will be different across different quantiles $\tau$.
In other words, the effect size $\beta(\tau)$ will not be a constant function of $\tau$.

To test this hypothesis, the quantile effect $\beta(\tau)$ is estimated for each quantile $\tau$, with estimates $\hat{\beta}(\tau)$ and standard errors $SE(\hat{\beta}(\tau))$.
QUAIL then assesses the evidence of vQTLs by looking at the integrated effect $\beta_{QI} = \int_{0}^{0.5}[\beta(1-\tau) - \beta(\tau)]d\tau$.
If the null hypothesis of no vQTLs is true, then $\beta_{QI}$ should be close to zero.

The applications of quantile regression on biobank data can also be found at [Pozarickij et al., 2019](https://www.nature.com/articles/s42003-019-0387-5) and [Wang et al., 2024](https://www.nature.com/articles/s41467-024-50726-x), where the detected vQTLs were then linked to evidence of GxE or GxG interactions.


## *Using FASH*

Now, we will try to approach this problem using the FASH method.
Specifically, for each of the $N$ SNPs $\{G_1, ..., G_N\}$, we compute their quantile regression effects $\{\hat{\beta}_i(\tau_j)\}$ and standard errors $\{SE(\hat{\beta}_i(\tau_j))\}$, at a set of quantiles $\{\tau_1, ..., \tau_J\}$.
We then assume the following model for the estimated quantile effects:
\[
\hat{\beta}_i(\tau_j) \overset{ind}{\sim} N(\beta_i(\tau_j), SE(\hat{\beta}_i(\tau_j))^2),
\]
where $\beta_i(\tau)|\pi_0,...,\pi_K \overset{iid}{\sim} \sum_{k=0}^{K} \pi_k\text{IWP}_1(\sigma_k)$.
For a function $g \sim \text{IWP}_1(\sigma)$, the prior is given by:
\[
\frac{\partial}{\partial \tau}\beta(\tau) = \sigma_k\xi(\tau),
\]
where $\beta(0)$ is assigned a diffuse prior and $\xi(\tau)$ is the standard Gaussian white noise.

The weight $\pi_0$ corresponds to the base model where $\sigma_0 = 0$ and $\beta(\tau) = \text{span}\{1\}$.

## *Simulation Setup*

To assess the performance of FASH, we simulate $N = 10000$ datasets of G and Y.

- In the first $N_A = 1000$ datasets, the G is assumed to affect Y on its variance level (vQTLs).
- In the next $N_B = 1000$ datasets, the G is assumed to affect Y on its mean lev (not vQTLs).
- In the next $N_C = 1000$ datasets, the G is assumed to affect Y on its mean and variance levels (vQTLs).
- For the other $N_D = 7000$ datasets, the G is assumed to have no effect on Y (not vQTLs).

The true effect, if exists, is assumed to be normally distributed with mean 0 and standard deviation `beta_sd`.

Once the data is simulated, we can perform quantile regression on each dataset to obtain the estimates $\hat{\beta}(\tau)$ and standard errors $SE(\hat{\beta}(\tau))$.

```{r eval=TRUE, echo=FALSE}
perform_rq <- function(data, tau_vec = seq(0.1, 0.9, by = 0.1)){
  beta_vec <- c()
  se_vec <- c()
  n <- nrow(data)

  # Perform quantile regression for each tau
  for (i in seq_along(tau_vec)) {
    tau <- tau_vec[i]
    mod <- rq(Y ~ G, data = data, tau = tau)
    summ_mod <- summary(mod, se = "boot")$coefficients
    beta_vec <- c(beta_vec, summ_mod[2, 1])
    se_vec <- c(se_vec, summ_mod[2, 2])
  }
  
  return(data.frame(tau = tau_vec, beta = beta_vec, se = se_vec))
}

simulate_data <- function(n, maf, beta_sd, sigma, case = "none"){
  # simulate G, with MAF = maf
  G <- rbinom(n, 2, maf)
  
  # simulate Y
  if(case == "mean"){
    beta <- rnorm(1, mean = 0, sd = beta_sd)
    Y <- rnorm(n, mean = beta * G, sd = sigma)
  } else if(case == "variance"){
    beta <- rnorm(1, mean = 0, sd = beta_sd)
    Y <- rnorm(n, mean = 0, sd = sqrt(abs(sigma^2 + (beta * G))))
  } else if(case == "both"){
    beta1 <- rnorm(1, mean = 0, sd = beta_sd); beta2 <- rnorm(1, mean = 0, sd = beta_sd)
    Y <- rnorm(n, mean = beta1 * G, sd = sqrt(abs(sigma^2 + (beta2 * G))))
  } else {
    Y <- rnorm(n, mean = 0, sd = sigma)
  }
  
  return(data.frame(G = G, Y = Y))
}
```

Here we can visualize one example of the quantile regression results.

```{r eval=TRUE, echo=FALSE}
set.seed(123)
data_try <- simulate_data(n = 20000, maf = 0.4, beta_sd = 0.3, sigma = 1, case = "both")
result <- perform_rq(data_try, tau_vec = seq(0.1, 0.9, by = 0.1), bootstrap = F)
plot(result$tau, result$beta, ylim = c(-1, 1), ylab = "beta est", xlab = "tau")
lines(result$tau, result$beta + 1.96 * result$se, lty = 2)
lines(result$tau, result$beta - 1.96 * result$se, lty = 2)
```

Now, let's do the simulation with FASH:

```{r eval=TRUE, echo=FALSE}
set.seed(123)  # For reproducibility
n <- 20000      # Number of observations per dataset
maf <- 0.3     # Minor allele frequency
beta_sd <- 0.3   # Effect size standard deviation
sigma <- 1     # Standard deviation
tau_vec <- seq(0.1, 0.9, by = 0.1)  # Quantiles for regression
N_A <- 500; N_B <- 500; N_C <- 500; N_D <- 3500  # Number of datasets for each case
num_datasets <- N_A + N_B + N_C + N_D # Total number of datasets
```


```{r eval=FALSE, echo=TRUE}
# Parameters
set.seed(123)  # For reproducibility
n <- 8000      # Number of observations per dataset
maf <- 0.3     # Minor allele frequency
beta_sd <- 0.3   # Effect size standard deviation
sigma <- 1     # Standard deviation
tau_vec <- seq(0.1, 0.9, by = 0.1)  # Quantiles for regression
N_A <- 50; N_B <- 50; N_C <- 50; N_D <- 350  # Number of datasets for each case
num_datasets <- N_A + N_B + N_C + N_D # Total number of datasets

# Initialize matrices to store beta estimates and standard errors
beta_matrix <- matrix(NA, nrow = num_datasets, ncol = length(tau_vec))
se_matrix <- matrix(NA, nrow = num_datasets, ncol = length(tau_vec))

# Generate datasets and perform quantile regression
for (i in 1:num_datasets) {
  if (i <= N_A) {
    case <- "variance"
  } else if (i <= (N_A + N_B)) {
    case <- "mean"
  } else if (i <= (N_A + N_B + N_C)) {
    case <- "both"
  } else {
    case <- "none"
  }
  
  # Simulate the data
  data <- simulate_data(n = n, maf = maf, beta_sd = beta_sd, sigma = sigma, case = case)
  
  # Perform quantile regression
  result <- perform_rq(data, tau_vec = tau_vec)
  
  # print how many datasets have been simulated in a message
  if(i %% 10 == 0){
    print(paste0(i, " datasets have been simulated."))
  }
  
  # Store beta estimates and standard errors
  beta_matrix[i, ] <- result$beta
  se_matrix[i, ] <- result$se
}

# Output matrices
print(dim(beta_matrix))  # Check dimensions
print(dim(se_matrix))    # Check dimensions
```

```{r eval=FALSE, echo=FALSE}
datasets <- list()
for (i in 1:num_datasets) {
  datasets[[i]] <- data.frame(tau = tau_vec, beta = beta_matrix[i,], se = se_matrix[i,])
}
save(datasets, file = paste0(data_dir, "/datasets.rda"))
```




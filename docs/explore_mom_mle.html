<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ziang Zhang" />

<meta name="date" content="2025-02-24" />

<title>Comparing two estimators for \pi_0</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">resultsummary</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="dynamic_eQTL.html">Simulation</a>
</li>
<li>
  <a href="covid_example.html">COVID-19 Example</a>
</li>
<li>
  <a href="expression.html">Gene Expression Example</a>
</li>
<li>
  <a href="dynamic_eQTL_real.html">Dynamic eQTLs</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/AgueroZZ/resultsummary">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Comparing two estimators for <span
class="math inline">\(\pi_0\)</span></h1>
<h4 class="author">Ziang Zhang</h4>
<h4 class="date">2025-02-24</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2025-02-25
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>FASHresultsummary/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges">
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted
changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges"
class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown is untracked by Git. To know which version of the R
Markdown file created these results, you’ll want to first commit it to
the Git repo. If you’re still working on the analysis, you can ignore
this warning. When you’re finished, you can run
<code>wflow_publish</code> to commit the R Markdown file and build the
HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20240507code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20240507)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20240507code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20240507)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomAgueroZZFASHresultsummarytree7393e94b22d704749fa336abd691fdd4f7bdd8c3targetblank7393e94a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/AgueroZZ/FASHresultsummary/tree/7393e94b22d704749fa336abd691fdd4f7bdd8c3" target="_blank">7393e94</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomAgueroZZFASHresultsummarytree7393e94b22d704749fa336abd691fdd4f7bdd8c3targetblank7393e94a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/AgueroZZ/FASHresultsummary/tree/7393e94b22d704749fa336abd691fdd4f7bdd8c3" target="_blank">7393e94</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.DS_Store
    Ignored:    analysis/.Rhistory
    Ignored:    code/.DS_Store
    Ignored:    code/.Rhistory
    Ignored:    code/cpp/.DS_Store
    Ignored:    code/function/.DS_Store
    Ignored:    data/.DS_Store
    Ignored:    data/Iyer/.DS_Store
    Ignored:    data/expression_data/.DS_Store
    Ignored:    output/.DS_Store
    Ignored:    output/Iyer/.DS_Store
    Ignored:    output/example/.DS_Store
    Ignored:    output/example/figure/
    Ignored:    output/expression/.DS_Store
    Ignored:    output/simulation_pollution/.DS_Store
    Ignored:    output/simulation_pollution/figure/
    Ignored:    output/vQTL_correlated/
    Ignored:    thought_process

Untracked files:
    Untracked:  analysis/explore_mom_mle.Rmd
    Untracked:  code/dynamic_eQTL_real/
    Untracked:  data/dynamic_eQTL_real/
    Untracked:  output/dynamic_eQTL_real/
    Untracked:  overdispersion_is_important.R

Unstaged changes:
    Modified:   analysis/_site.yml
    Modified:   analysis/dynamic_eQTL_real.rmd
    Modified:   code/function/functions_simulating.R
    Modified:   code/function/functions_simulation.R
    Modified:   code/function/functions_simulation_eQTL_test.R
    Modified:   output/simulation_dynamic_eQTL/fash_fit_1.RData
    Modified:   output/simulation_dynamic_eQTL/fash_fit_1_noisy.RData
    Modified:   output/simulation_dynamic_eQTL/fash_fit_2.RData
    Modified:   output/simulation_dynamic_eQTL/fash_fit_2_noisy.RData
    Modified:   output/simulation_dynamic_eQTL/fash_fit_2_noisy_pen.RData

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">
<p>
There are no past versions. Publish this analysis with
<code>wflow_publish()</code> to start tracking its development.
</p>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Let <span class="math inline">\(\mathbf{L}\)</span> denote the
likelihood matrix of size <span class="math inline">\(N\times
(K+1)\)</span>, where <span class="math inline">\(N\)</span> is the
number of data(sets) and <span class="math inline">\(K+1\)</span> is the
number of mixture components. Each entry of <span
class="math inline">\(\mathbf{L}_{ik}\)</span> is the likelihood of the
<span class="math inline">\(i\in[N]\)</span> data under the <span
class="math inline">\(k\in\{0,1,...,K\}\)</span> mixture component.</p>
<p>The MLE of <span class="math inline">\(\pi_0\)</span> denoted as
<span class="math inline">\(\hat{\pi}_0\)</span> is defined as <span
class="math display">\[
\hat{\pi}_0 = \arg \max_{\pi_0} \sum_{i=1}^N \log \big[\sum_{k=0}^K
\pi_k L_{ik}\big].
\]</span></p>
<p>The MOM estimator of <span class="math inline">\(\pi_0\)</span>
denoted as <span class="math inline">\(\tilde{\pi}_0\)</span> is defined
as <span class="math display">\[
\tilde{\pi}_0 = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(\tilde{Z_i}=0),
\]</span> where <span class="math inline">\(\tilde{Z_i} = \arg \max_{k}
L_{ik}\)</span>.</p>
<p></p>
<ul>
<li><p>Without any model-misspecification, the MLE <span
class="math inline">\(\hat{\pi}_0\)</span> is the best estimator for
<span class="math inline">\(\pi_0\)</span> (in terms of MSE), whereas
the MoM estimator <span class="math inline">\(\tilde{\pi}_0\)</span> is
biased.</p></li>
<li><p>With model-misspecification, the MLE <span
class="math inline">\(\hat{\pi}_0\)</span> is highly unstable (large
variance), whereas the MoM estimator <span
class="math inline">\(\tilde{\pi}_0\)</span> is biased but
stable.</p></li>
</ul>
<pre><code>
Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>The following objects are masked from &#39;package:stats&#39;:

    filter, lag</code></pre>
<pre><code>The following objects are masked from &#39;package:base&#39;:

    intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>pred_step_selected &lt;- 8
B &lt;- 30
grid_vec = seq(0, 2, by = 0.5)
sigma = 0.3</code></pre>
</div>
<div id="without-model-misspecification" class="section level2">
<h2>Without Model-Misspecification</h2>
<p>We will write some functions to carry out the simulation. First, we
will consider the case when there is no model-misspecification. The data
are simulated from mixture of IWP2, and we are fitting the same
model.</p>
<pre class="r"><code>estimates_higher &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.7, 0.15, 0.15),
    N = 300,
    sigma = sigma, 
    snr = 2,
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 2, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_higher &lt;- rbind(estimates_higher, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<p>Let’s visualize the estimates of <span
class="math inline">\(\pi_0\)</span> from MLE and MoM.</p>
<pre class="r"><code>estimates_higher %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.85, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.85, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Obviously the MoM estimator has an downward bias (due to <span
class="math inline">\(\pi_0 &gt; 0.5\)</span>), as well as higher
variance compared to the MLE.</p>
<p>We can calculate the mean squared error (MSE) of the two
estimators:</p>
<pre class="r"><code>estimates_higher %&gt;%
  summarise(
    mse_mle = mean((pi0_mle - 0.85)^2),
    mse_mom = mean((pi0_mom - 0.85)^2)
  )</code></pre>
<pre><code>      mse_mle    mse_mom
1 0.002462116 0.01500889</code></pre>
<p>The MLE estimator is better in terms of MSE.</p>
<p>Look at the specific bias and variance of the two estimators:</p>
<pre class="r"><code>estimates_higher %&gt;%
  summarise(
    bias_mle = mean(pi0_mle - 0.85),
    bias_mom = mean(pi0_mom - 0.85),
    var_mle = var(pi0_mle),
    var_mom = var(pi0_mom)
  )</code></pre>
<pre><code>     bias_mle   bias_mom     var_mle      var_mom
1 0.003078696 -0.1211111 0.002537212 0.0003527458</code></pre>
<p>Just to confirm, let’s try again when <span
class="math inline">\(\pi_0 &lt; 0.5\)</span> without model
mis-specification. This time, we expect the MLE still performs better,
and the MoM suffers from upward bias.</p>
<pre class="r"><code>estimates_lower &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.1, 0.1, 0.8),
    N = 300,
    sigma = sigma,
    snr = 2,
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 2, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_lower &lt;- rbind(estimates_lower, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<pre class="r"><code>estimates_lower %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.2, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.2, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Compute the mean squared error (MSE) of the two estimators:</p>
<pre class="r"><code>estimates_lower %&gt;%
  summarise(
    mse_mle = mean((pi0_mle - 0.2)^2),
    mse_mom = mean((pi0_mom - 0.2)^2)
  )</code></pre>
<pre><code>      mse_mle    mse_mom
1 0.005011658 0.07065741</code></pre>
<p>Compute bias and variance</p>
<pre class="r"><code>estimates_lower %&gt;%
  summarise(
    bias_mle = mean(pi0_mle - 0.2),
    bias_mom = mean(pi0_mom - 0.2),
    var_mle = var(pi0_mle),
    var_mom = var(pi0_mom)
  )</code></pre>
<pre><code>    bias_mle  bias_mom     var_mle      var_mom
1 0.03174283 0.2645556 0.004142122 0.0006907918</code></pre>
<p>Again, the MLE estimator is better in terms of MSE, and the MoM
estimator is biased but stable.</p>
</div>
<div id="with-model-misspecification" class="section level2">
<h2>With Model-Misspecification</h2>
<p>This type we are fitting mixture of IWP1 even though the data are
simulated from mixture of IWP2.</p>
<pre class="r"><code>estimates_higher_miss &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.7, 0.15, 0.15),
    N = 300,
    sigma = sigma,
    snr = 2,
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 1, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_higher_miss &lt;- rbind(estimates_higher_miss, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<p>Let’s visualize the estimates of <span
class="math inline">\(\pi_0\)</span> from MLE and MoM.</p>
<pre class="r"><code>estimates_higher_miss %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.7, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.7, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Compute the mean squared error (MSE) of the two estimators:</p>
<pre class="r"><code>estimates_higher_miss %&gt;%
  summarise(
    mse_mle = mean((pi0_mle - 0.7)^2),
    mse_mom = mean((pi0_mom - 0.7)^2)
  )</code></pre>
<pre><code>     mse_mle     mse_mom
1 0.01101396 0.005231481</code></pre>
<p>Now the MoM estimator is better in terms of MSE, although both
estimators are biased.</p>
<p>Compute bias and variance</p>
<pre class="r"><code>estimates_higher_miss %&gt;%
  summarise(
    bias_mle = mean(pi0_mle - 0.7),
    bias_mom = mean(pi0_mom - 0.7),
    var_mle = var(pi0_mle),
    var_mom = var(pi0_mom)
  )</code></pre>
<pre><code>    bias_mle    bias_mom      var_mle      var_mom
1 -0.1029839 -0.07055556 0.0004223644 0.0002621328</code></pre>
<p>Another example when <span class="math inline">\(\pi_0 &lt;
0.5\)</span> with model mis-specification.</p>
<pre class="r"><code>estimates_lower_miss &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.2, 0.4, 0.4),
    N = 300,
    sigma = sigma,
    snr = 2,
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 1, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_lower_miss &lt;- rbind(estimates_lower_miss, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<p>Let’s visualize the estimates of <span
class="math inline">\(\pi_0\)</span> from MLE and MoM.</p>
<pre class="r"><code>estimates_lower_miss %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.2, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.2, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Compute the mean squared error (MSE) of the two estimators:</p>
<pre class="r"><code>estimates_lower_miss %&gt;%
  summarise(
    mse_mle = mean((pi0_mle - 0.2)^2),
    mse_mom = mean((pi0_mom - 0.2)^2)
  )</code></pre>
<pre><code>      mse_mle      mse_mom
1 0.009720578 0.0002811111</code></pre>
<p>Compute bias and variance</p>
<pre class="r"><code>estimates_lower_miss %&gt;%
  summarise(
    bias_mle = mean(pi0_mle - 0.2),
    bias_mom = mean(pi0_mom - 0.2),
    var_mle = var(pi0_mle),
    var_mom = var(pi0_mom)
  )</code></pre>
<pre><code>     bias_mle    bias_mom      var_mle      var_mom
1 -0.09538003 0.007444444 0.0006447176 0.0002334738</code></pre>
<p>Again, although the MoM estimator has a slight upward bias, it is
more stable compared to the MLE estimator, and better in terms of
MSE.</p>
</div>
<div id="as-the-data-becomes-noisy" class="section level2">
<h2>As the data becomes noisy…</h2>
<p>Here we contrast the two estimators as the data becomes noisier
(<span class="math inline">\(\sigma\)</span> increases) without
considering model-misspecification.</p>
<p>This time to make the effect of <span
class="math inline">\(\sigma\)</span> clear, we will no longer keep the
same Signal-to-Noise Ratio (SNR) for datasets under the alternative
hypothesis.</p>
<p>First, we consider the case when <span class="math inline">\(\sigma =
0.1\)</span> (not noisy):</p>
<pre class="r"><code>estimates_higher_not_noisy &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.7, 0.15, 0.15),
    N = 300,
    sigma = sigma/3, 
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 2, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_higher_not_noisy &lt;- rbind(estimates_higher_not_noisy, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<pre class="r"><code>estimates_higher_not_noisy %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.85, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.85, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Then, we consider the case when <span class="math inline">\(\sigma =
3\)</span> (very noisy):</p>
<pre class="r"><code>estimates_higher_noisy &lt;- data.frame(pi0_mle = numeric(0), pi0_mom = numeric(0))
progress &lt;- txtProgressBar(min = 0, max = B, style = 3)</code></pre>
<pre><code>  |                                                                              |                                                                      |   0%</code></pre>
<pre class="r"><code>for (i in 1:B) {
  setTxtProgressBar(progress, i)
  datasets &lt;- sim_dataset(
    pi = c(0.7, 0.15, 0.15),
    N = 300,
    sigma = sigma*10, 
    seed = i,
    pred_step = pred_step_selected,
    plot = F
  )
  L_matrix &lt;- getLmat(datasets, grid_vec, order = 2, num_cores = 4, pred_step = pred_step_selected)
  estimates_new &lt;- compute_estimates(L_matrix, penalty = 1)
  estimates_higher_noisy &lt;- rbind(estimates_higher_noisy, estimates_new)
}</code></pre>
<pre><code>  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  13%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  23%  |                                                                              |===================                                                   |  27%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  40%  |                                                                              |==============================                                        |  43%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |========================================                              |  57%  |                                                                              |==========================================                            |  60%  |                                                                              |============================================                          |  63%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  70%  |                                                                              |===================================================                   |  73%  |                                                                              |======================================================                |  77%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |=============================================================         |  87%  |                                                                              |===============================================================       |  90%  |                                                                              |=================================================================     |  93%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%</code></pre>
<pre class="r"><code>estimates_higher_noisy %&gt;%
  ggplot(aes(x = pi0_mle, y = pi0_mom)) +
  geom_point() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_hline(yintercept = 0.85, linetype = &quot;dashed&quot;) +
  geom_vline(xintercept = 0.85, linetype = &quot;dashed&quot;) +
  labs(x = &quot;MLE&quot;, y = &quot;MoM&quot;, title = &quot;Estimates of pi0 from MLE and MoM&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/explore_mom_mle.Rmd/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>It seems like compared to the model-misspecification, the noise has
even stronger effect on the MLE estimator, making it even more
unstable.</p>
</div>
<div id="bias-in-mom" class="section level2">
<h2>Bias in MoM</h2>
<p>To see the bias in the MoM estimator <span
class="math inline">\(\tilde{\pi}_0\)</span>, we assume that for each
dataset <span class="math inline">\(i\)</span>, <span
class="math inline">\(P[\tilde{Z}_i=0|Z_i=0] = \theta_n\)</span> and
<span class="math inline">\(P[\tilde{Z}_i=0|Z_i\neq0] =
1-\alpha_n\)</span>. It is clear that <span
class="math inline">\(\theta_n \rightarrow 1\)</span>, and <span
class="math inline">\(\alpha_n \rightarrow 1\)</span> as <span
class="math inline">\(n\rightarrow\infty\)</span>.</p>
<p>Based on the classical asymptomatic consistency of the MLE estimator,
it is clear that <span class="math inline">\(\tilde{Z_i}\)</span> is
consistent for <span class="math inline">\(Z_i\)</span> as <span
class="math inline">\(n\to\infty\)</span>, hence <span
class="math inline">\(\theta_n\)</span> converges to 0.</p>
<p>For now, assume the true expectation <span
class="math inline">\(\mathbb{E}[\mathbb{I}(Z_i=0)] =
\pi_0\)</span>.</p>
<p>The MoM estimator as <span class="math inline">\(N \rightarrow
\infty\)</span> converges to <span class="math display">\[\tilde{\pi}_0
= \frac{\sum_{i=1}^N\mathbb{I}(\tilde{Z_i} =0)}{N}
\overset{p}{\rightarrow}
\mathbb{E}[\mathbb{I}(\tilde{Z}_i=0)].\]</span></p>
<p>Therefore, as <span class="math inline">\(N \rightarrow
\infty\)</span>, the MoM estimator converges to <span
class="math display">\[\begin{equation}
\begin{aligned}
\tilde{\pi}_0 \overset{p}{\rightarrow}
\mathbb{E}[\mathbb{I}(\tilde{Z}_i=0)] &amp;=
\mathbb{E}[\mathbb{I}(\tilde{Z}_i=0)|Z_i=0]\pi_0 +
\mathbb{E}[\mathbb{I}(\tilde{Z}_i=0)|Z_i\neq0](1-\pi_0) \\
&amp;= \theta_n\pi_0 + (1-\alpha_n)(1-\pi_0).
\end{aligned}
\end{equation}\]</span></p>
<p>The bias of the MoM estimator is <span
class="math display">\[\begin{equation}
\begin{aligned}
\text{Bias}(\tilde{\pi}_0) &amp;= \mathbb{E}[\tilde{\pi}_0] - \pi_0 \\
&amp;= \theta_n\pi_0 + (1-\alpha_n)(1-\pi_0) - \pi_0 \\
&amp;= (1-\alpha_n) - (2-\theta_n-\alpha_n)\pi_0.
\end{aligned}
\end{equation}\]</span></p>
<p>Assuming for simplicity that <span class="math inline">\(\theta_n
\approx \alpha_n\)</span>, the bias is approximately <span
class="math display">\[
\text{Bias}(\tilde{\pi}_0) \approx (1 - \alpha_n) - 2(1-\alpha_n)\pi_0.
\]</span></p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.1 (2023-06-16)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Monterey 12.7.4

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] dplyr_1.1.4   ggplot2_3.5.1

loaded via a namespace (and not attached):
 [1] sass_0.4.9           utf8_1.2.4           generics_0.1.3      
 [4] stringi_1.8.4        lattice_0.22-6       digest_0.6.37       
 [7] magrittr_2.0.3       BayesGP_0.1.3        evaluate_1.0.1      
[10] grid_4.3.1           fastmap_1.2.0        rprojroot_2.0.4     
[13] workflowr_1.7.1      jsonlite_1.8.9       Matrix_1.6-4        
[16] mixsqp_0.3-54        promises_1.3.0       fansi_1.0.6         
[19] scales_1.3.0         jquerylib_0.1.4      cli_3.6.3           
[22] rlang_1.1.4          LaplacesDemon_16.1.6 munsell_0.5.1       
[25] withr_3.0.2          cachem_1.1.0         yaml_2.3.10         
[28] tools_4.3.1          parallel_4.3.1       colorspace_2.1-1    
[31] httpuv_1.6.15        vctrs_0.6.5          R6_2.5.1            
[34] lifecycle_1.0.4      git2r_0.33.0         stringr_1.5.1       
[37] fs_1.6.4             irlba_2.3.5.1        pkgconfig_2.0.3     
[40] pillar_1.9.0         bslib_0.8.0          later_1.3.2         
[43] gtable_0.3.6         glue_1.8.0           Rcpp_1.0.13-1       
[46] highr_0.11           xfun_0.48            tibble_3.2.1        
[49] tidyselect_1.2.1     rstudioapi_0.16.0    knitr_1.48          
[52] farver_2.1.2         htmltools_0.5.8.1    rmarkdown_2.28      
[55] labeling_0.4.3       compiler_4.3.1       fashr_0.1.1         </code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
